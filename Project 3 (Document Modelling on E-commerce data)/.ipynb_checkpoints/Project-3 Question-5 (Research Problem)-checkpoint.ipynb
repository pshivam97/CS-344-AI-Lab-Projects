{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Research Question : Implementing Machine Learning models for Review Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:14: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Loading Necessary Libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from pandas.core import datetools\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import statsmodels.api as sm\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "import re\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, SimpleRNN\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.sparse.linalg import svds\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.sparse import csc_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "1ba6ceef0d5c8aa38531eb2da54a0f47238501d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Labeled Dataset : 22641\n",
      "[[-0.00475422 -0.05088965]\n",
      " [ 0.08621034 -0.22376388]\n",
      " [ 0.05883809 -0.20286163]\n",
      " ...\n",
      " [-0.00090118 -0.29795682]\n",
      " [ 0.14559843 -0.2644313 ]\n",
      " [ 0.09049927 -0.13752938]]\n"
     ]
    }
   ],
   "source": [
    "#Clothing_ID = 862\n",
    "\n",
    "# corpus_pandas_dataFrame = pd.read_csv(\"../input/Womens Clothing E-Commerce Reviews.csv\")\n",
    "# corpus_with_particular_ID = corpus_pandas_dataFrame[corpus_pandas_dataFrame[\"Clothing ID\"] == Clothing_ID]\n",
    "# corpus_with_particular_ID = corpus_with_particular_ID.dropna(subset=['Review Text'])\n",
    "# review_text = corpus_with_particular_ID[\"Review Text\"]\n",
    "# label_dataset = corpus_with_particular_ID[\"Recommended IND\"]\n",
    "\n",
    "corpus_pandas_dataFrame = pd.read_csv(\"../input/Womens Clothing E-Commerce Reviews.csv\")\n",
    "entire_corpus = corpus_pandas_dataFrame.dropna(subset=['Review Text'])\n",
    "review_text = entire_corpus[\"Review Text\"]\n",
    "label_dataset = entire_corpus[\"Recommended IND\"]\n",
    "#print(review_text)\n",
    "\n",
    "X_set = list() # This will be a list of strings, where each string will be a \"document\"\n",
    "y_set = list()\n",
    "\n",
    "## Pre-processing Corpus\n",
    "for each_review,label in zip(review_text,label_dataset):\n",
    "    preprocessed_review = each_review.lower() # Lower-casing each document\n",
    "    preprocessed_review = re.sub(r'[^A-Za-z ]', '', preprocessed_review) # removing Punctuations from each document\n",
    "    X_set.append(preprocessed_review)\n",
    "    y_set.append(label)\n",
    "\n",
    "labeled_X_y_set = list(zip(X_set,y_set))\n",
    "print(\"Length of Labeled Dataset :\",len(labeled_X_y_set))#,\"\\n\",labeled_X_y_set) # print the pre-processed corpus\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "                    ## Stemming and Lemmatization - Applying to the pre-processed corpus\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for each_document_index in range(len(X_set)):\n",
    "    list_of_words = X_set[each_document_index].strip().split()\n",
    "    \n",
    "    for each_word_index in range(len(list_of_words)) :\n",
    "        list_of_words[each_word_index] = lemmatizer.lemmatize(list_of_words[each_word_index])\n",
    "    \n",
    "    X_set[each_document_index] = ' '.join(list_of_words)\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "                                # STOPWORDS Removal from the Corpus #\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "stopWords = stopwords.words('english')\n",
    "\n",
    "## Pre-processing Stopwords\n",
    "for stopWord_index in range(len(stopWords)):\n",
    "    stopWords[stopWord_index] = stopWords[stopWord_index].lower() # Lower-casing\n",
    "    stopWords[stopWord_index] = re.sub(r'[^A-Za-z ]','',stopWords[stopWord_index]) # removing Punctuations\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0, stop_words=stopWords, strip_accents='ascii')\n",
    "docs_tf = vectorizer.fit_transform(X_set)\n",
    "vocabulary_terms = vectorizer.get_feature_names()\n",
    "docs_query_tf = vectorizer.transform(X_set) \n",
    "transformer = TfidfTransformer(smooth_idf = False)\n",
    "tfidf = transformer.fit_transform(docs_query_tf.toarray())\n",
    "#print(vocabulary_terms)\n",
    "\n",
    "U, s, V = svds(tfidf.T)\n",
    "K = 2 # number of components\n",
    "\n",
    "docs_rep = np.dot(np.diag(s[-K:]), V[-K:, :]).T # D x K matrix \n",
    "terms_rep = np.dot(U[:,-K:], np.diag(s[-K:])) # V x K matrix\n",
    "print(docs_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "498813ff5ad29378bff4d07c0e176b7965183ab2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22641 entries, 0 to 23485\n",
      "Data columns (total 11 columns):\n",
      "Unnamed: 0                 22641 non-null int64\n",
      "Clothing ID                22641 non-null int64\n",
      "Age                        22641 non-null int64\n",
      "Title                      19675 non-null object\n",
      "Review Text                22641 non-null object\n",
      "Rating                     22641 non-null int64\n",
      "Recommended IND            22641 non-null int64\n",
      "Positive Feedback Count    22641 non-null int64\n",
      "Division Name              22628 non-null object\n",
      "Department Name            22628 non-null object\n",
      "Class Name                 22628 non-null object\n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "entire_corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "207729861703c24a3dc8be1a0e7fc01e6efd52d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22641.000000</td>\n",
       "      <td>22641.000000</td>\n",
       "      <td>22641.000000</td>\n",
       "      <td>22641.000000</td>\n",
       "      <td>22641.000000</td>\n",
       "      <td>22641.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11740.849035</td>\n",
       "      <td>919.332362</td>\n",
       "      <td>43.280376</td>\n",
       "      <td>4.183561</td>\n",
       "      <td>0.818868</td>\n",
       "      <td>2.630582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6781.957509</td>\n",
       "      <td>202.266874</td>\n",
       "      <td>12.326980</td>\n",
       "      <td>1.115762</td>\n",
       "      <td>0.385136</td>\n",
       "      <td>5.786164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5872.000000</td>\n",
       "      <td>861.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11733.000000</td>\n",
       "      <td>936.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17621.000000</td>\n",
       "      <td>1078.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23485.000000</td>\n",
       "      <td>1205.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0           ...             Positive Feedback Count\n",
       "count  22641.000000           ...                        22641.000000\n",
       "mean   11740.849035           ...                            2.630582\n",
       "std     6781.957509           ...                            5.786164\n",
       "min        0.000000           ...                            0.000000\n",
       "25%     5872.000000           ...                            0.000000\n",
       "50%    11733.000000           ...                            1.000000\n",
       "75%    17621.000000           ...                            3.000000\n",
       "max    23485.000000           ...                          122.000000\n",
       "\n",
       "[8 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entire_corpus.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "75a0425aecbf07bb8c1104ddcc538164f63d7f8b"
   },
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "294796fff49fe1dc8688aa86a3a91e0cd6f9f51b"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f05da6ed9e8bb98652ed025133d16ca01a390305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression Model : 0.8154443254817987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(docs_rep, y_set, test_size=0.33,random_state=42)\n",
    "model = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\n",
    "print(\"Accuracy of the Logistic Regression Model :\",model.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9291da885a50f4070721f9036b91f77c0619982e"
   },
   "source": [
    "## Support Vector Machines(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "6fb0c8d754e7bfd4aa81a41fdf57a2dc8432ebd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the SVM Model : 0.8155781584582441\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "C = 1.0 # SVM regularization parameter\n",
    "X_train, X_test, y_train, y_test = train_test_split(docs_rep, y_set, test_size=0.33,random_state=42)\n",
    "svc = SVC(kernel='linear', C=1,gamma='auto').fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy of the SVM Model :\",svc.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8a65daeef166c3b01a36b06312343022a2324d8"
   },
   "source": [
    "## Logistic Regression vs. SVM\n",
    "\n",
    "We discern that both the classification methods end up displaying **approximately same score(accuracy)**.\n",
    "- *Accuracy of the Logistic Regression Model : 0.8154443254817987*\n",
    "- *Accuracy of the SVM Model : 0.8155781584582441*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
